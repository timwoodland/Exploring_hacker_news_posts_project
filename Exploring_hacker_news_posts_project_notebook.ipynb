{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data\n",
    "CSV file read in.\n",
    "\n",
    "CSV file downloaded from [Kaggle](https://www.kaggle.com/hacker-news/hacker-news-posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in csv\n",
    "opened_file = open('HN_posts_year_to_Sep_26_2016.csv')\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "hn_data = list(read_file)\n",
    "hn_header = hn_data[0]\n",
    "hn = hn_data[1:]\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line after each row\n",
    "\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of data\n",
    "\n",
    "The data set has 7 columns and 393,119 rows of data (excl. the header)\n",
    "\n",
    "The columns are:\n",
    "\n",
    "|0|1|2|3|4|5|6|\n",
    "|:---|:---|:---|:---|:---|:---|:---|\n",
    "|id|title|url|num_points|num_comments|author|created_at|\n",
    "|id of the post|title of the post|the url of the item being linked to|the number of upvotes the post received|the number of comments the post received|the name of the account that made the post|the date and time the post was made (\"mm/dd/yyyy hh:mm\" Eastern Time in the US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  7 \n",
      "\n",
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of columns: \", len(hn_header), \"\\n\")\n",
    "print(hn_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of data:  293119 \n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "\n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "\n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "\n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "\n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows of data: \", len(hn), \"\\n\")\n",
    "\n",
    "explore_data(hn,0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate data into three lists: ask_posts, show_posts, and other_posts\n",
    "\n",
    "The three lists as based on the title starting with \"ask_posts\" or \"show_posts\". Where a title does not start with one of these two options, the data is added to the other_posts list of lists.\n",
    "\n",
    "The three list of lists have the following lengths:\n",
    "- ask_posts 9,139\n",
    "- show_posts 1,158\n",
    "- other_posts 273,822\n",
    "\n",
    "These three list add up to the total rows of the original dataset, which is 293,119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in ask_posts:  9139\n",
      "Number of rows in show_posts:  10158\n",
      "Number of rows in other_posts:  273822\n",
      "\n",
      " The first 5 rows of the ask_posts list of lists: \n",
      "\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "\n",
      "\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "\n",
      "\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "\n",
      "\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "\n",
      "\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    \n",
    "    if title.startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(\"Number of rows in ask_posts: \", len(ask_posts))\n",
    "print(\"Number of rows in show_posts: \", len(show_posts))\n",
    "print(\"Number of rows in other_posts: \", len(other_posts))\n",
    "\n",
    "print(\"\\n\", \"The first 5 rows of the ask_posts list of lists:\", \"\\n\")\n",
    "explore_data(ask_posts, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of comments for each post type\n",
    "\n",
    "The average number of comments for each post type is:\n",
    "- ask_post average number of comments: 10.39\n",
    "- show_post average number of comments: 4.89\n",
    "\n",
    "It is evident that the ask_posts receive significantly more comments as the average is approximately double that of the show_posts average.\n",
    "\n",
    "Based on this finding, this project will now focus on ask_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments per ask_post is:  10.393478498741656\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print(\"The average number of comments per ask_post is: \", avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments per show_post is:  4.886099625910612\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"The average number of comments per show_post is: \", avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between time of day of post and number of comments\n",
    "\n",
    "We will now calculate the posts created in each hour of the day, along with the number of comments recieved, and then determine the average number of comments a post receives for each hours of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    dt_created = dt.datetime.strptime(row[6], \"%m/%d/%Y %H:%M\")\n",
    "    num_comments = int(row[4])\n",
    "    results_list.append([dt_created, num_comments])\n",
    "    \n",
    "\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in results_list:\n",
    "    hour = row[0].strftime(\"%H\")\n",
    "    num_comments = row[1]\n",
    "    \n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += num_comments\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = num_comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02', 11.137546468401487]\n",
      "\n",
      "\n",
      "['01', 7.407801418439717]\n",
      "\n",
      "\n",
      "['22', 8.804177545691905]\n",
      "\n",
      "\n",
      "['21', 8.687258687258687]\n",
      "\n",
      "\n",
      "['19', 7.163043478260869]\n",
      "\n",
      "\n",
      "['17', 9.449744463373083]\n",
      "\n",
      "\n",
      "['15', 28.676470588235293]\n",
      "\n",
      "\n",
      "['14', 9.692007797270955]\n",
      "\n",
      "\n",
      "['13', 16.31756756756757]\n",
      "\n",
      "\n",
      "['11', 8.96474358974359]\n",
      "\n",
      "\n",
      "['10', 10.684397163120567]\n",
      "\n",
      "\n",
      "['09', 6.653153153153153]\n",
      "\n",
      "\n",
      "['07', 7.013274336283186]\n",
      "\n",
      "\n",
      "['03', 7.948339483394834]\n",
      "\n",
      "\n",
      "['23', 6.696793002915452]\n",
      "\n",
      "\n",
      "['20', 8.749019607843136]\n",
      "\n",
      "\n",
      "['16', 7.713298791018998]\n",
      "\n",
      "\n",
      "['08', 9.190661478599221]\n",
      "\n",
      "\n",
      "['00', 7.5647840531561465]\n",
      "\n",
      "\n",
      "['18', 7.94299674267101]\n",
      "\n",
      "\n",
      "['12', 12.380116959064328]\n",
      "\n",
      "\n",
      "['04', 9.7119341563786]\n",
      "\n",
      "\n",
      "['06', 6.782051282051282]\n",
      "\n",
      "\n",
      "['05', 8.794258373205741]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    num_posts = counts_by_hour[hour]\n",
    "    num_comments = comments_by_hour[hour]\n",
    "    avg = num_comments / num_posts\n",
    "    avg_by_hour.append([hour, avg])\n",
    "    \n",
    "explore_data(avg_by_hour, 0, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.676470588235293, '15']\n",
      "\n",
      "\n",
      "[16.31756756756757, '13']\n",
      "\n",
      "\n",
      "[12.380116959064328, '12']\n",
      "\n",
      "\n",
      "[11.137546468401487, '02']\n",
      "\n",
      "\n",
      "[10.684397163120567, '10']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "\n",
    "explore_data(sorted_swap, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top five hours for `Ask Posts` comments are:\n",
      "15:00: 28.68 average comments per post\n",
      "13:00: 16.32 average comments per post\n",
      "12:00: 12.38 average comments per post\n",
      "02:00: 11.14 average comments per post\n",
      "10:00: 10.68 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"The top five hours for `Ask Posts` comments are:\")\n",
    "for row in sorted_swap[:5]:\n",
    "    avg = row[0]\n",
    "    hour = dt.datetime.strptime(row[1], \"%H\").strftime(\"%H:%M\")\n",
    "    print(\"{a}: {b:.2f} average comments per post\".format(a = hour, b = avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of findings for relationship between time of day of post and number of comments\n",
    "From the summary above we can see that top times to create a \"Ask Post\" and receive the maximum number of comments are around the middle of the day to mid afternoon US Eastern Time. We can also see that 2AM appears to be a populare time, which may be as a result of the inmpact of a different timezone.\n",
    "\n",
    "For those based in Melbourne, Australia (like me), these times convert to:\n",
    "1. 15:00 --> 05:00\n",
    "2. 13:00 --> 03:00\n",
    "3. 12:00 --> 02:00\n",
    "4. 02:00 --> 16:00\n",
    "5. 10:00 --> 00:00"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
